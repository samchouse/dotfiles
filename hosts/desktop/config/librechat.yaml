# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: false

# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']

#
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

actions:
  allowedDomains: []

mcpServers: {}

# Definition of custom endpoints
endpoints:
  assistants:
    disableBuilder: true
  # agents:
  # disableBuilder: true
  custom:
    - name: "LiteLLM"
      apiKey: "${LITELLM_API_KEY}"
      baseURL: "http://host.docker.internal:4044"
      models:
        default: ["openai/gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "openrouter/google/gemini-2.0-flash"
      dropParams: ["stop"]
      modelDisplayLabel: "LiteLLM"

fileConfig:
  avatarSizeLimit: 5
